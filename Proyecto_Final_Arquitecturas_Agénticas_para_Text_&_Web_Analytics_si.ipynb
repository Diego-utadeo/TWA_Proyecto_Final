{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spzM9CQK7T0P",
        "outputId": "580d29b4-136a-4830-d6be-2352a5ddfb0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting es-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.8.0/es_core_news_md-3.8.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4 requests spacy textblob scikit-learn\n",
        "\n",
        "# Modelo spaCy en español\n",
        "!python -m spacy download es_core_news_md\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import re, json, datetime\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "nlp = spacy.load(\"es_core_news_md\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai\n",
        "#!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg5lo10MvYgI",
        "outputId": "f2dc5cc1-8b10-42ad-9186-b759f00da3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.53.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.12.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LLM Gemini"
      ],
      "metadata": {
        "id": "-JYMu88pysbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ⚠️ SOLO para uso personal; evita subir esto a ningún repositorio\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"Aqui va la llave de google\""
      ],
      "metadata": {
        "id": "zNYhMfYtv8Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "# Crea el cliente usando la variable de entorno GEMINI_API_KEY\n",
        "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "9WNsNxKbwCQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_llm(prompt: str, model_name: str = \"gemini-2.5-flash\") -> str:\n",
        "     \"\"\"\n",
        "     Envía un prompt de texto al modelo Gemini y devuelve la respuesta en texto plano.\n",
        "     - prompt: instrucción o contexto que le pasas al LLM.\n",
        "     - model_name: puedes usar gemini-2.5-flash (rápido) o gemini-2.5-pro (más potente).\n",
        "     \"\"\"\n",
        "     response = client.models.generate_content(\n",
        "         model=model_name,\n",
        "         contents=prompt\n",
        "     )\n",
        "    # La respuesta ya viene estructurada; text te da todo concatenado\n",
        "     return response.text"
      ],
      "metadata": {
        "id": "lJRuJz5XwG6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompt = \"Explica en 3 frases cuál es el objetivo de un sistema multi-agente para análisis de reseñas de smartphones.\"\n",
        "respuesta = call_llm(test_prompt)\n",
        "print(respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viwxrDEGwJhv",
        "outputId": "c4e64cf9-73ce-4a00-da33-c5bb6c43178e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El objetivo principal es extraer de forma eficiente y exhaustiva información valiosa de grandes volúmenes de reseñas de smartphones. Para ello, el sistema distribuye tareas especializadas entre agentes autónomos que colaboran, como identificar sentimientos, extraer características o detectar problemas comunes. Así, se logra una comprensión profunda y multidimensional de las preferencias y experiencias de los usuarios, imposible de alcanzar con métodos tradicionales.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class MASState:\n",
        "    query: str\n",
        "    urls: List[Dict[str, Any]] = field(default_factory=list)\n",
        "    documents: List[Dict[str, Any]] = field(default_factory=list)\n",
        "    nlp_results: Dict[str, Any] = field(default_factory=dict)\n",
        "    factcheck_results: List[Dict[str, Any]] = field(default_factory=list)\n",
        "    created_at: str = field(default_factory=lambda: datetime.datetime.now().isoformat())\n",
        "\n",
        "class BaseAgent:\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "\n",
        "    def run(self, state: MASState) -> MASState:\n",
        "        raise NotImplementedErro"
      ],
      "metadata": {
        "id": "an1TqIj3wMMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agente de Busqueda Web"
      ],
      "metadata": {
        "id": "dWU4h26YzSq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SmartphoneWebSearchAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Agente de búsqueda que devuelve URLs de artículos de análisis de smartphones,\n",
        "    no páginas de índice.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name=\"smartphone_search\", max_results=5):\n",
        "        super().__init__(name)\n",
        "        self.max_results = max_results\n",
        "\n",
        "    def run(self, state: MASState) -> MASState:\n",
        "        # EJEMPLO: artículos concretos (ajusta las URLs a las que tú quieras analizar)\n",
        "        example_urls = [\n",
        "            {\n",
        "                \"url\": \"https://www.xataka.com/moviles/samsung-galaxy-s24-ultra-analisis-caracteristicas-precio-especificaciones\",\n",
        "                \"title\": \"Análisis Samsung Galaxy S24 Ultra\",\n",
        "                \"source\": \"Xataka\"\n",
        "            },\n",
        "            {\n",
        "                \"url\": \"https://www.xataka.com/analisis/apple-iphone-15-pro-max-analisis-caracteristicas-precio-especificaciones\",\n",
        "                \"title\": \"Análisis iPhone 15 Pro Max\",\n",
        "                \"source\": \"Xataka\"\n",
        "            },\n",
        "            {\n",
        "                \"url\": \"https://www.xataka.com/moviles/xiaomi-14-analisis-caracteristicas-precio-especificaciones\",\n",
        "                \"title\": \"Análisis Xiaomi 14\",\n",
        "                \"source\": \"Xataka\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        state.urls = example_urls[:self.max_results]\n",
        "        print(f\"[{self.name}] Se seleccionaron {len(state.urls)} artículos concretos.\")\n",
        "        return state"
      ],
      "metadata": {
        "id": "0661ediPwOyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agente Scraper"
      ],
      "metadata": {
        "id": "Sa_fji3Jzeu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScraperAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Agente encargado de descargar y limpiar el texto de las páginas web.\n",
        "    Intenta centrarse en el cuerpo del artículo.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name=\"scraper\"):\n",
        "        super().__init__(name)\n",
        "        self.headers = {\n",
        "            \"User-Agent\": (\n",
        "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                \"Chrome/122.0.0.0 Safari/537.36\"\n",
        "            )\n",
        "        }\n",
        "\n",
        "    def extract_main_text(self, soup: BeautifulSoup) -> str:\n",
        "        # 1. Intentar con la etiqueta <article>\n",
        "        article = soup.find(\"article\")\n",
        "        if article:\n",
        "            text = article.get_text(separator=\" \", strip=True)\n",
        "            if len(text.split()) > 100:\n",
        "                return text\n",
        "\n",
        "        # 2. Intentar con contenedores comunes\n",
        "        candidates = []\n",
        "        for selector in [\"main\", \"div#content\", \"div.article-body\", \"div.entry-content\"]:\n",
        "            node = soup.select_one(selector)\n",
        "            if node:\n",
        "                t = node.get_text(separator=\" \", strip=True)\n",
        "                candidates.append(t)\n",
        "\n",
        "        candidates = [c for c in candidates if len(c.split()) > 100]\n",
        "        if candidates:\n",
        "            # Devolver el texto más largo de los candidatos\n",
        "            return max(candidates, key=len)\n",
        "\n",
        "        # 3. Fallback: texto completo de la página (limpiando scripts, etc.)\n",
        "        for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
        "            tag.decompose()\n",
        "        text = soup.get_text(separator=\" \", strip=True)\n",
        "        return text\n",
        "\n",
        "    def run(self, state: MASState) -> MASState:\n",
        "        docs = []\n",
        "        for meta in state.urls:\n",
        "            url = meta[\"url\"]\n",
        "            try:\n",
        "                print(f\"[{self.name}] Descargando: {url}\")\n",
        "                resp = requests.get(url, headers=self.headers, timeout=15)\n",
        "                if resp.status_code == 200:\n",
        "                    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "                    text = self.extract_main_text(soup)\n",
        "\n",
        "                    # Filtro: descartar textos muy cortos\n",
        "                    if len(text.split()) < 150:\n",
        "                        print(f\"  - Advertencia: texto muy corto en {url} ({len(text.split())} palabras). Se descarta.\")\n",
        "                        continue\n",
        "\n",
        "                    docs.append({\n",
        "                        \"url\": url,\n",
        "                        \"source\": meta.get(\"source\", \"\"),\n",
        "                        \"title\": meta.get(\"title\", \"\"),\n",
        "                        \"text\": text\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"  - Error HTTP {resp.status_code} en {url}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  - Error al acceder a {url}: {e}\")\n",
        "\n",
        "        state.documents = docs\n",
        "        print(f\"[{self.name}] Se obtuvieron {len(docs)} documentos con texto suficiente.\")\n",
        "        return state"
      ],
      "metadata": {
        "id": "aKEesfzJwdJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agente NLP (NER + Sentimiento + Clustering)"
      ],
      "metadata": {
        "id": "wNywFBdLznkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SmartphoneNLPAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Agente que realiza:\n",
        "    - Extracción de entidades (NER)\n",
        "    - Análisis de sentimiento\n",
        "    - Clustering de temas (TF-IDF + KMeans)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name=\"smartphone_nlp\", n_clusters=3):\n",
        "        super().__init__(name)\n",
        "        self.n_clusters = n_clusters\n",
        "\n",
        "    def extract_entities(self, text: str):\n",
        "        doc = nlp(text)\n",
        "        ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "        return ents\n",
        "\n",
        "    def sentiment_score(self, text: str) -> float:\n",
        "        blob = TextBlob(text)\n",
        "        return blob.sentiment.polarity\n",
        "\n",
        "    def cluster_topics(self, docs: List[str]):\n",
        "        \"\"\"\n",
        "        Devuelve:\n",
        "        - labels: lista con el id de cluster por documento\n",
        "        - top_terms: términos representativos por cluster\n",
        "        \"\"\"\n",
        "        if len(docs) < 2:\n",
        "            # Con un solo documento no tiene sentido agrupar: todo a cluster 0\n",
        "            return [0] * len(docs), {}\n",
        "\n",
        "        try:\n",
        "            vectorizer = TfidfVectorizer(max_features=3000)\n",
        "            X = vectorizer.fit_transform(docs)\n",
        "            k = min(self.n_clusters, len(docs))\n",
        "            model = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
        "            labels = model.fit_predict(X)\n",
        "            # Convertimos el array a lista para evitar problemas de truth value\n",
        "            labels = list(labels)\n",
        "\n",
        "            terms = vectorizer.get_feature_names_out()\n",
        "            top_terms = {}\n",
        "            for cluster_id in range(k):\n",
        "                center = model.cluster_centers_[cluster_id]\n",
        "                top_idx = center.argsort()[-10:]\n",
        "                top_terms[cluster_id] = [terms[i] for i in top_idx]\n",
        "\n",
        "            return labels, top_terms\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[{self.name}] Error en cluster_topics: {e}\")\n",
        "            return [0] * len(docs), {}\n",
        "\n",
        "    def run(self, state: MASState) -> MASState:\n",
        "        if not state.documents:\n",
        "            print(f\"[{self.name}] No hay documentos para procesar NLP.\")\n",
        "            state.nlp_results = {\"docs\": [], \"cluster_terms\": {}}\n",
        "            return state\n",
        "\n",
        "        print(f\"[{self.name}] Iniciando análisis NLP sobre {len(state.documents)} documentos...\")\n",
        "\n",
        "        # Textos recortados\n",
        "        texts = []\n",
        "        for d in state.documents:\n",
        "            text = d.get(\"text\", \"\") or \"\"\n",
        "            texts.append(text[:4000])\n",
        "\n",
        "        labels, top_terms = self.cluster_topics(texts)\n",
        "\n",
        "        doc_results = []\n",
        "        for i, d in enumerate(state.documents):\n",
        "            raw_text = d.get(\"text\", \"\") or \"\"\n",
        "            snippet = raw_text[:2000]\n",
        "\n",
        "            ents = self.extract_entities(snippet) if snippet else []\n",
        "            sent = self.sentiment_score(snippet) if snippet else 0.0\n",
        "            if labels is not None and len(labels) > i:\n",
        "                cluster = int(labels[i])\n",
        "            else:\n",
        "                cluster = 0\n",
        "\n",
        "            doc_results.append({\n",
        "                \"url\": d.get(\"url\", \"\"),\n",
        "                \"source\": d.get(\"source\", \"\"),\n",
        "                \"title\": d.get(\"title\", \"\"),\n",
        "                \"sentiment\": sent,\n",
        "                \"cluster\": cluster,\n",
        "                \"entities\": ents\n",
        "            })\n",
        "\n",
        "        state.nlp_results = {\n",
        "            \"docs\": doc_results,\n",
        "            \"cluster_terms\": top_terms\n",
        "        }\n",
        "\n",
        "        print(f\"[{self.name}] Análisis NLP completado.\")\n",
        "        return state"
      ],
      "metadata": {
        "id": "eZGKupdJwfkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agente FactCheck"
      ],
      "metadata": {
        "id": "eY9mAL2rztYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FactCheckAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Agente que extrae afirmaciones verificables del texto y las marca\n",
        "    como 'Requiere verificación adicional'.\n",
        "    Versión robusta: solo actúa si hay texto suficiente y filtra respuestas meta del LLM.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name=\"fact_checker\", max_claims=3):\n",
        "        super().__init__(name)\n",
        "        self.max_claims = max_claims\n",
        "\n",
        "    def extract_claims_with_llm(self, text: str, n: int = 3):\n",
        "        \"\"\"\n",
        "        Usa el LLM para extraer hasta n afirmaciones verificables sobre smartphones.\n",
        "        Si el texto está vacío, devuelve lista vacía.\n",
        "        \"\"\"\n",
        "        if not text or not text.strip():\n",
        "            # No hay texto para analizar\n",
        "            return []\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Extrae hasta {n} afirmaciones verificables sobre smartphones\n",
        "        (hechos concretos, medibles u objetivamente comprobables) del siguiente texto.\n",
        "        Devuélvelas como una lista numerada, una afirmación por línea.\n",
        "        No escribas explicaciones adicionales, solo las afirmaciones.\n",
        "\n",
        "        Texto:\n",
        "        {text}\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            resp = call_llm(prompt)\n",
        "            # Separar por líneas y limpiar\n",
        "            raw_lines = [c.strip(\"- \").strip() for c in resp.split(\"\\n\") if c.strip()]\n",
        "\n",
        "            # Filtro básico: descartar líneas meta (ej. \"Claro, ...\" o muy cortas)\n",
        "            claims = []\n",
        "            for line in raw_lines:\n",
        "                lower = line.lower()\n",
        "                if len(line.split()) < 5:\n",
        "                    continue\n",
        "                if any(ini in lower for ini in [\"claro\", \"necesito que\", \"por favor\", \"cuando me lo proporciones\"]):\n",
        "                    continue\n",
        "                claims.append(line)\n",
        "\n",
        "            return claims[:n]\n",
        "\n",
        "        except NotImplementedError:\n",
        "            # Fallback de demo: usar frases largas del texto\n",
        "            sentences = re.split(r\"[.!?]\", text)\n",
        "            fallback_claims = [s.strip() for s in sentences if len(s.split()) > 6]\n",
        "            return fallback_claims[:n]\n",
        "\n",
        "    def run(self, state: MASState) -> MASState:\n",
        "        print(f\"[{self.name}] Iniciando extracción de afirmaciones para fact-checking...\")\n",
        "\n",
        "        # 1. Validar que haya documentos\n",
        "        if not state.documents:\n",
        "            print(f\"[{self.name}] No hay documentos, no se puede hacer fact-checking.\")\n",
        "            state.factcheck_results = []\n",
        "            return state\n",
        "\n",
        "        # 2. Combinar texto de los documentos (recortado para no saturar)\n",
        "        combined_parts = []\n",
        "        for d in state.documents:\n",
        "            txt = d.get(\"text\", \"\")\n",
        "            if txt and txt.strip():\n",
        "                combined_parts.append(txt[:1500])\n",
        "\n",
        "        combined = \" \".join(combined_parts)\n",
        "\n",
        "        if not combined.strip():\n",
        "            print(f\"[{self.name}] Texto combinado vacío, no se puede hacer fact-checking.\")\n",
        "            state.factcheck_results = []\n",
        "            return state\n",
        "\n",
        "        # 3. Extraer afirmaciones con LLM (o fallback)\n",
        "        claims = self.extract_claims_with_llm(combined, n=self.max_claims)\n",
        "\n",
        "        results = []\n",
        "        for c in claims:\n",
        "            results.append({\n",
        "                \"claim\": c,\n",
        "                \"status\": \"Requiere verificación adicional\",\n",
        "                \"evidence_urls\": []   # En esta versión ligera aún no buscamos evidencia\n",
        "            })\n",
        "\n",
        "        state.factcheck_results = results\n",
        "        print(f\"[{self.name}] Se identificaron {len(results)} afirmaciones candidatas.\")\n",
        "        return state"
      ],
      "metadata": {
        "id": "CyhfQ6ctxFw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agente Coordinador / Supervisor"
      ],
      "metadata": {
        "id": "VTicoL1Hz2sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CoordinatorAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Orquesta todo el pipeline:\n",
        "    - Búsqueda web\n",
        "    - Scraping\n",
        "    - NLP\n",
        "    - Fact-checking\n",
        "    - Generación del informe final\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, search_agent, scraper_agent, nlp_agent, fact_agent, name=\"coordinator\"):\n",
        "        super().__init__(name)\n",
        "        self.search_agent = search_agent\n",
        "        self.scraper_agent = scraper_agent\n",
        "        self.nlp_agent = nlp_agent\n",
        "        self.fact_agent = fact_agent\n",
        "\n",
        "    def run(self, state: MASState) -> MASState:\n",
        "        print(f\"\\n[{self.name}] Iniciando pipeline multi-agente...\\n\")\n",
        "\n",
        "        # 1. Agente de búsqueda\n",
        "        state = self.search_agent.run(state)\n",
        "\n",
        "        # 2. Scraper\n",
        "        state = self.scraper_agent.run(state)\n",
        "\n",
        "        # Validación crítica: ¿hay documentos?\n",
        "        if not state.documents:\n",
        "            print(f\"[{self.name}] No se obtuvieron documentos tras el scraping. Pipeline detenido.\")\n",
        "            return state\n",
        "\n",
        "        # 3. NLP\n",
        "        state = self.nlp_agent.run(state)\n",
        "\n",
        "        # 4. Fact-checking\n",
        "        state = self.fact_agent.run(state)\n",
        "\n",
        "        print(f\"\\n[{self.name}] Pipeline completado correctamente.\\n\")\n",
        "        return state\n",
        "\n",
        "    def build_report(self, state: MASState) -> str:\n",
        "        \"\"\"\n",
        "        Usa el LLLM para generar el informe final basado en state.\n",
        "        \"\"\"\n",
        "        print(f\"[{self.name}] Generando informe con LLM...\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Eres un analista de inteligencia de mercado.\n",
        "        Genera un informe ejecutivo claro y profesional basado en los resultados siguientes:\n",
        "\n",
        "        Documentos analizados:\n",
        "        {state.documents}\n",
        "\n",
        "        Resultados de NLP:\n",
        "        {state.nlp_results}\n",
        "\n",
        "        Afirmaciones identificadas para fact-checking:\n",
        "        {state.factcheck_results}\n",
        "\n",
        "        Entrega un informe en secciones:\n",
        "        - Resumen ejecutivo\n",
        "        - Percepción general de las marcas\n",
        "        - Temas principales (clusters)\n",
        "        - Sentimiento por documento o marca\n",
        "        - Afirmaciones para verificación\n",
        "        - Conclusiones\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            report = call_llm(prompt)\n",
        "        except Exception as e:\n",
        "            report = f\"No fue posible generar el informe con LLM. Error: {e}\"\n",
        "\n",
        "        return report"
      ],
      "metadata": {
        "id": "RPXet2ILxelu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Informe"
      ],
      "metadata": {
        "id": "59LFVkSYz6fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Analiza cómo perciben los medios latinoamericanos a las marcas Samsung, Apple y Xiaomi en reseñas recientes de smartphones.\"\n",
        "state = MASState(query=query)\n",
        "\n",
        "search_agent = SmartphoneWebSearchAgent()\n",
        "scraper_agent = ScraperAgent()\n",
        "nlp_agent = SmartphoneNLPAgent(n_clusters=3)\n",
        "fact_agent = FactCheckAgent()\n",
        "\n",
        "coordinator = CoordinatorAgent(\n",
        "    search_agent=search_agent,\n",
        "    scraper_agent=scraper_agent,\n",
        "    nlp_agent=nlp_agent,\n",
        "    fact_agent=fact_agent\n",
        ")\n",
        "\n",
        "state = coordinator.run(state)\n",
        "informe = coordinator.build_report(state)\n",
        "print(informe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grEb_Aqlxxe_",
        "outputId": "4aab11f6-7cf8-448b-992f-dff1d84db3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[coordinator] Iniciando pipeline multi-agente...\n",
            "\n",
            "[smartphone_search] Se seleccionaron 3 artículos concretos.\n",
            "[scraper] Descargando: https://www.xataka.com/moviles/samsung-galaxy-s24-ultra-analisis-caracteristicas-precio-especificaciones\n",
            "[scraper] Descargando: https://www.xataka.com/analisis/apple-iphone-15-pro-max-analisis-caracteristicas-precio-especificaciones\n",
            "[scraper] Descargando: https://www.xataka.com/moviles/xiaomi-14-analisis-caracteristicas-precio-especificaciones\n",
            "[scraper] Se obtuvieron 3 documentos con texto suficiente.\n",
            "[smartphone_nlp] Iniciando análisis NLP sobre 3 documentos...\n",
            "[smartphone_nlp] Análisis NLP completado.\n",
            "[fact_checker] Iniciando extracción de afirmaciones para fact-checking...\n",
            "[fact_checker] Se identificaron 3 afirmaciones candidatas.\n",
            "\n",
            "[coordinator] Pipeline completado correctamente.\n",
            "\n",
            "[coordinator] Generando informe con LLM...\n",
            "## Informe Ejecutivo de Inteligencia de Mercado: Análisis Comparativo de Smartphones Premium (Q1 2024)\n",
            "\n",
            "**Fecha:** 11 de Junio de 2024\n",
            "\n",
            "**Analista:** [Tu Nombre/Departamento de Inteligencia de Mercado]\n",
            "\n",
            "### 1. Resumen Ejecutivo\n",
            "\n",
            "El presente informe proporciona un análisis comparativo de la percepción de mercado sobre tres smartphones insignia: el Samsung Galaxy S24 Ultra, el Apple iPhone 15 Pro Max y el Xiaomi 14, basado en reseñas de Xataka. Los dispositivos muestran un alto nivel de competencia en rendimiento, diseño, pantalla y cámara, con cada marca destacando en áreas específicas.\n",
            "\n",
            "*   **Samsung Galaxy S24 Ultra:** Se posiciona como un dispositivo de equilibrio general, con una pantalla líder en el mercado y una fuerte apuesta por la inteligencia artificial (Galaxy AI). Sin embargo, enfrenta críticas por la necesidad de optimización de su cámara y problemas de sobrecalentamiento.\n",
            "*   **Apple iPhone 15 Pro Max:** Destaca por su diseño en titanio, autonomía excepcional y significativas mejoras en el procesamiento de imagen de su cámara, especialmente el teleobjetivo 5x y el HDR. Las preocupaciones se centran en la falta de innovación en la pantalla y el sobrecalentamiento.\n",
            "*   **Xiaomi 14:** Se presenta como una opción \"premium compacta\" con un rendimiento muy fluido y un sistema de cámaras versátil, elogiado particularmente por su teleobjetivo y modo macro. Sus principales áreas de mejora residen en la calidad de grabación de vídeo y el brillo máximo de la pantalla.\n",
            "\n",
            "El sentimiento general de las revisiones es variado, con el iPhone 15 Pro Max recibiendo una valoración más positiva, seguido de un Xiaomi 14 con un sentimiento neutro y un Samsung Galaxy S24 Ultra con una ligera inclinación negativa, principalmente debido a las expectativas no totalmente cumplidas en la cámara y el rendimiento térmico. Se han identificado afirmaciones clave que requieren verificación adicional para su completa validación.\n",
            "\n",
            "### 2. Percepción General de las Marcas\n",
            "\n",
            "*   **Samsung (Galaxy S24 Ultra):**\n",
            "    *   **Positivo:** Equilibrio general impecable, la mejor pantalla del mercado (especialmente por la capa antirreflejos Gorilla Glass Armor), siete años de actualizaciones (gran garantía de futuro), S-Pen integrado, IA innovadora (Galaxy AI).\n",
            "    *   **Negativo:** La cámara, aunque buena, necesita una actualización para optimizar HDR y detalles finos. Problemas de sobrecalentamiento \"notable\" pese al Snapdragon 8 Gen 3. Carga rápida considerada lenta para su segmento. La IA es potente, pero su utilidad diaria depende mucho del perfil del usuario.\n",
            "*   **Apple (iPhone 15 Pro Max):**\n",
            "    *   **Positivo:** Diseño y ergonomía mejorados gracias al titanio y biseles más estrechos. Autonomía excepcional. Cámaras con importantes mejoras en HDR, teleobjetivo 5x y modo retrato automático. USB-C como cambio relevante y bienvenido. Software (iOS 17) maduro y estable. Potencia bruta del procesador.\n",
            "    *   **Negativo:** Pantalla sin mejoras técnicas significativas respecto a la generación anterior. El sobrecalentamiento es \"aleatorio como preocupante\". La carga rápida sigue siendo lenta en comparación con rivales Android. El botón de acción requiere \"dejar pulsado\" lo que resta inmediatez. La isla dinámica sigue siendo un elemento visual disruptivo.\n",
            "*   **Xiaomi (Xiaomi 14):**\n",
            "    *   **Positivo:** Sensación \"compacta premium\" muy valorada. Excelente experiencia fotográfica, destacando el teleobjetivo 3.2x y el modo macro. Rendimiento fantástico y fluido gracias al Snapdragon 8 Gen 3 y HyperOS. Carga rápida de 90W muy eficiente.\n",
            "    *   **Negativo:** La grabación de vídeo está por debajo de los \"titanes de su categoría\". La trasera es \"muy, muy sucia\" (huellas). El brillo máximo de la pantalla podría ser mayor a pleno sol. La ubicación del sensor de huellas es incómoda. HyperOS, aunque fluido, es muy similar a MIUI con bloatware.\n",
            "\n",
            "### 3. Temas Principales (Clusters)\n",
            "\n",
            "Los documentos analizados se agrupan en los siguientes clusters temáticos, identificados por los términos más frecuentes en cada uno:\n",
            "\n",
            "*   **Cluster 0: Apple iPhone 15 Pro Max**\n",
            "    *   **Términos clave:** `del`, `pro`, `apple`, `en`, `al`, `el`, `iphone`, `la`, `que`, `de`\n",
            "    *   **Análisis:** Este cluster se centra inequívocamente en el dispositivo de Apple, el iPhone 15 Pro Max, abarcando su diseño, características de \"Pro\" y su posición dentro de la marca Apple.\n",
            "*   **Cluster 1: Xiaomi 14**\n",
            "    *   **Términos clave:** `no`, `lo`, `con`, `la`, `en`, `es`, `el`, `xiaomi`, `que`, `de`\n",
            "    *   **Análisis:** Este cluster está dominado por la marca \"Xiaomi\" y el modelo \"14\", reflejando el análisis detallado de sus prestaciones y usabilidad.\n",
            "*   **Cluster 2: Samsung Galaxy S24 Ultra**\n",
            "    *   **Términos clave:** `ultra`, `del`, `s24`, `galaxy`, `que`, `la`, `el`, `en`, `samsung`, `de`\n",
            "    *   **Análisis:** Centrado en el \"Samsung Galaxy S24 Ultra\", este cluster aborda las particularidades de este modelo, incluyendo aspectos relacionados con su versión \"Ultra\" y sus innovaciones.\n",
            "\n",
            "### 4. Sentimiento por Documento o Marca\n",
            "\n",
            "La evaluación de sentimiento de cada documento proporciona una perspectiva sobre la reacción general del analista ante el dispositivo:\n",
            "\n",
            "*   **Apple iPhone 15 Pro Max:** Sentimiento predominantemente **positivo (0.17)**. La revisión resalta múltiples mejoras y fortalezas que contribuyen a una valoración favorable.\n",
            "*   **Xiaomi 14:** Sentimiento **neutro (0.00)**. El análisis presenta un balance equitativo entre puntos fuertes y áreas de mejora, sin inclinarse marcadamente hacia lo positivo o negativo.\n",
            "*   **Samsung Galaxy S24 Ultra:** Sentimiento ligeramente **negativo (-0.13)**. Aunque el documento reconoce muchas virtudes, las críticas a la cámara, el sobrecalentamiento y la carga rápida influyen en una valoración general menos optimista.\n",
            "\n",
            "### 5. Afirmaciones para Verificación\n",
            "\n",
            "Las siguientes afirmaciones fueron identificadas para verificación, pero la evidencia necesaria para confirmarlas o refutarlas **no se encuentra presente en los documentos analizados ni en los resultados de NLP proporcionados**. Se requiere una búsqueda de información adicional para su validación.\n",
            "\n",
            "*   1. El iPhone 15 Pro Max tiene una pantalla Super Retina XDR de 6,7 pulgadas con una tasa de refresco de 1 a 120 Hz. (Estado: Requiere verificación adicional)\n",
            "*   2. El Xiaomi 14 está equipado con un procesador Snapdragon 8 Gen 3. (Estado: Requiere verificación adicional)\n",
            "*   3. El Samsung Galaxy S24 Ultra tiene un cuerpo rematado en titanio. (Estado: Requiere verificación adicional)\n",
            "\n",
            "### 6. Conclusiones\n",
            "\n",
            "El mercado de smartphones de gama alta en 2024 se caracteriza por una intensa competencia, donde cada fabricante busca diferenciarse a través de innovaciones específicas y la consolidación de sus fortalezas.\n",
            "\n",
            "*   **Innovación y Diferenciación:** Samsung apuesta por la inteligencia artificial y una pantalla excepcional, reforzando su promesa de longevidad con siete años de actualizaciones. Apple se enfoca en la madurez de su ecosistema, la potencia del hardware y una fotografía computacional muy refinada, además de la adopción del USB-C. Xiaomi busca su nicho con una propuesta de gama alta en un formato más compacto y una versatilidad fotográfica destacada en teleobjetivo y macro.\n",
            "*   **Desafíos Comunes:** La gestión térmica de los potentes procesadores sigue siendo un punto débil para Samsung y Apple, afectando la experiencia de usuario. La velocidad de carga, aunque mejor en Xiaomi, es un área donde Apple y Samsung podrían innovar más para satisfacer las expectativas del segmento premium. La calidad de vídeo sigue siendo un diferenciador importante, con Apple manteniendo una clara ventaja.\n",
            "*   **Implicaciones para el Mercado:** Los consumidores en el segmento premium valoran el rendimiento, la calidad de la cámara, el diseño y el soporte a largo plazo. Las marcas que logren un equilibrio entre estas características, a la vez que resuelvan los puntos débiles reportados (como el sobrecalentamiento o la consistencia de la cámara), serán las que mantengan una ventaja competitiva. La integración efectiva y percibida de la IA será clave para justificar el alto coste de los dispositivos futuros.\n"
          ]
        }
      ]
    }
  ]
}